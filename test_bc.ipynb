{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74458582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os \n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "# from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "from skill_helpers import * \n",
    "import sys \n",
    "\n",
    "from top_down_env import CraftaxTopDownEnv\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "import argparse\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b94c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# --- must match your training definitions ---\n",
    "class ImageNormalizer:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32).view(3,1,1)\n",
    "        self.std  = torch.clamp(torch.tensor(std, dtype=torch.float32).view(3,1,1), min=1e-3)\n",
    "    def __call__(self, x):  # x: [3,H,W] in [0,1]\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(c_in, c_out, kernel_size=k, stride=s, padding=p, bias=False)\n",
    "        self.bn   = torch.nn.BatchNorm2d(c_out)  # or GroupNorm if you switched\n",
    "        self.act  = torch.nn.GELU()\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class PolicyCNN(torch.nn.Module):\n",
    "    def __init__(self, n_actions=16):\n",
    "        super().__init__()\n",
    "        self.stem = torch.nn.Sequential(\n",
    "            ConvBlock(3, 32, k=7, s=2, p=3),\n",
    "            ConvBlock(32, 32),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.stage2 = torch.nn.Sequential(\n",
    "            ConvBlock(32, 64),\n",
    "            ConvBlock(64, 64),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.stage3 = torch.nn.Sequential(\n",
    "            ConvBlock(64, 128),\n",
    "            ConvBlock(128, 128),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.stage4 = torch.nn.Sequential(\n",
    "            ConvBlock(128, 256),\n",
    "            ConvBlock(256, 256),\n",
    "        )\n",
    "        self.head = torch.nn.Linear(256, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.head(x)\n",
    "\n",
    "# ---- inference helpers ----\n",
    "\n",
    "def load_policy(ckpt_path, device=None):\n",
    "    \"\"\"Load model + normalizer from a saved training checkpoint.\"\"\"\n",
    "    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    n_actions = int(ckpt['n_actions'])\n",
    "    model = PolicyCNN(n_actions=n_actions).to(device)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.eval()\n",
    "    normalizer = ImageNormalizer(ckpt['mean'], ckpt['std'])\n",
    "    return model, normalizer, device, n_actions\n",
    "\n",
    "def preprocess_frame(frame_hw3, normalizer, target=256):\n",
    "    \"\"\"\n",
    "    frame_hw3: numpy array [H,W,3], float32 in [0,1]\n",
    "    returns torch tensor [1,3,target,target]\n",
    "    \"\"\"\n",
    "    assert frame_hw3.ndim == 3 and frame_hw3.shape[2] == 3\n",
    "    x = torch.from_numpy(np.transpose(frame_hw3, (2,0,1))).float()   # [3,H,W]\n",
    "    x = F.interpolate(x.unsqueeze(0), size=(target, target), mode='bilinear', align_corners=False).squeeze(0)  # [3,T,T]\n",
    "    x = normalizer(x)\n",
    "    return x.unsqueeze(0)  # [1,3,T,T]\n",
    "\n",
    "@torch.no_grad()\n",
    "def act_greedy(model, normalizer, device, frame_hw3):\n",
    "    \"\"\"\n",
    "    Returns (action_id, probs) where probs is a numpy array length n_actions.\n",
    "    \"\"\"\n",
    "    x = preprocess_frame(frame_hw3, normalizer)            # [1,3,256,256]\n",
    "    x = x.to(device)\n",
    "    logits = model(x)                                      # [1,n_actions]\n",
    "    probs = torch.softmax(logits, dim=-1).squeeze(0)       # [n_actions]\n",
    "    action = int(torch.argmax(probs).item())\n",
    "    return action, probs.cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def act_sample(model, normalizer, device, frame_hw3, temperature=1.0):\n",
    "    x = preprocess_frame(frame_hw3, normalizer).to(device)\n",
    "    logits = model(x).squeeze(0)\n",
    "    if temperature != 1.0:\n",
    "        logits = logits / max(1e-6, float(temperature))\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    action = int(torch.multinomial(probs, num_samples=1).item())\n",
    "    return action, probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6628439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damionharvey/miniconda3/envs/hisd/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.6.1 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/damionharvey/miniconda3/envs/hisd/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "artifacts = joblib.load('Traces/stone_pickaxe_easy/pca_models/pca_model_750.joblib')\n",
    "scaler = artifacts['scaler']   # StandardScaler(with_std=False)\n",
    "pca = artifacts['pca']         # PCA(n_components=512)\n",
    "n_features_expected = scaler.mean_.shape[0]\n",
    "\n",
    "def get_pca_feat(obs):\n",
    "    arr = np.asarray(obs, dtype=np.float32)\n",
    "\n",
    "    # flatten into shape (1, features)\n",
    "    X = arr.reshape(1, -1)\n",
    "\n",
    "    # --- Apply scaler + PCA ---\n",
    "    X_centered = scaler.transform(X)\n",
    "    X_feats = pca.transform(X_centered)\n",
    "\n",
    "    return X_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c6ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_list = ['wood', 'stone', 'wood_pickaxe', 'stone_pickaxe', 'table']\n",
    "bc_models = {}\n",
    "\n",
    "for skill in skill_list:\n",
    "    ckpt_path = os.path.join('Traces/stone_pickaxe_easy', 'bc_checkpoints', f'{skill}_policy_cnn.pt')\n",
    "    bc_models[skill] = load_policy(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae05846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_start_models = load_pu_models('Traces/stone_pickaxe_easy/pu_start_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208421eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = CraftaxTopDownEnv(seed=1)\n",
    "# obs = env.reset()\n",
    "# done = False\n",
    "# total_reward = 0\n",
    "\n",
    "# all_obs = [obs.copy()]\n",
    "# all_actions = []\n",
    "\n",
    "# end_models_path = 'Traces/stone_pickaxe_easy/pu_end_models'\n",
    "\n",
    "# MAX_STEPS = 100\n",
    "# MAX_STEPS_PER_SKILL = 200  # optional guard; tune or remove\n",
    "# t = 0\n",
    "\n",
    "# def pick_executable_skill(pu_start_models, pca_obs, end_models_path):\n",
    "#     \"\"\"\n",
    "#     Return the first candidate skill whose end condition is NOT true on pca_obs.\n",
    "#     If no candidate is executable, return None.\n",
    "#     \"\"\"\n",
    "#     candidates = applicable_pu_start_models(\n",
    "#         pu_start_models, pca_obs, return_details=False\n",
    "#     )\n",
    "#     if not candidates:\n",
    "#         return None\n",
    "\n",
    "#     # Iterate candidates in the provided (assumed ranked) order\n",
    "#     for cand in candidates:\n",
    "#         is_end = end_state_prob_pu(end_models_path, cand, pca_obs)['is_end']\n",
    "#         if not is_end:\n",
    "#             return cand\n",
    "\n",
    "#     # All candidates already 'ended' for current state\n",
    "#     return None\n",
    "\n",
    "# while t < MAX_STEPS and not done:\n",
    "#     # 1) Choose a skill that is actually executable from the current state\n",
    "#     pca_obs = get_pca_feat(obs)\n",
    "#     skill_name = pick_executable_skill(pu_start_models, pca_obs, end_models_path)\n",
    "\n",
    "#     if skill_name is None:\n",
    "#         print(\"No executable skill found; breaking to avoid spin.\")\n",
    "#         break\n",
    "\n",
    "#     # 2) Execute the chosen skill until its end condition fires (or step caps/done)\n",
    "#     skill_steps = 0\n",
    "#     while t < MAX_STEPS and not done:\n",
    "#         print(\"Executing skill:\", skill_name)\n",
    "#         print(\"Step:\", t)\n",
    "\n",
    "#         pca_obs = get_pca_feat(obs)\n",
    "#         if end_state_prob_pu(end_models_path, skill_name, pca_obs)['is_end']:\n",
    "#             print(\"Skill ended:\", skill_name)\n",
    "#             break\n",
    "\n",
    "#         # Retrieve policy components for this skill\n",
    "#         model, normalizer, device, n_actions = bc_models[skill_name]\n",
    "\n",
    "#         # IMPORTANT: Ensure act_greedy expects 'obs' (raw image) vs transformed features.\n",
    "#         # If it needs normalized PCA features, replace 'obs' with that here.\n",
    "#         action, probs = act_greedy(model, normalizer, device, obs)\n",
    "\n",
    "#         # Step the environment\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         all_obs.append(obs.copy())\n",
    "#         all_actions.append(action)\n",
    "#         total_reward += reward\n",
    "\n",
    "#         t += 1\n",
    "#         skill_steps += 1\n",
    "\n",
    "#         # Optional per-skill safety cap\n",
    "#         if skill_steps >= MAX_STEPS_PER_SKILL:\n",
    "#             print(f\"Per-skill step cap hit for '{skill_name}'. Re-selecting skill.\")\n",
    "#             break\n",
    "\n",
    "# print(\"Total steps:\", t, \"Total reward:\", total_reward)\n",
    "# # Save observations as a GIF\n",
    "# frames = [(np.clip(f, 0, 1) * 255).astype(np.uint8) for f in all_obs]\n",
    "# imageio.mimsave(f\"craftax_run_auto_{1}_{total_reward}.gif\", frames, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d519a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-09-20 21:57:32,049:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/damionharvey/miniconda3/envs/hisd/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n",
      "2025-09-20 21:57:32,049 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/damionharvey/miniconda3/envs/hisd/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Craftax-Classic textures from cache.\n",
      "Textures successfully loaded from cache.\n",
      "\n",
      "=== Executing skill: wood ===\n",
      "Skill: wood | Step: 0\n",
      "Skill: wood | Step: 1\n",
      "Skill: wood | Step: 2\n",
      "Skill: wood | Step: 3\n",
      "Skill: wood | Step: 4\n",
      "Skill: wood | Step: 5\n",
      "Skill: wood | Step: 6\n",
      "Skill: wood | Step: 7\n",
      "Skill: wood | Step: 8\n",
      "Skill: wood | Step: 9\n",
      "Skill: wood | Step: 10\n",
      "Skill: wood | Step: 11\n",
      "Skill: wood | Step: 12\n",
      "Skill: wood | Step: 13\n",
      "Skill: wood | Step: 14\n",
      "Skill: wood | Step: 15\n",
      "Skill: wood | Step: 16\n",
      "Skill: wood | Step: 17\n",
      "Skill: wood | Step: 18\n",
      "Skill: wood | Step: 19\n",
      "Skill: wood | Step: 20\n",
      "Skill: wood | Step: 21\n",
      "Skill: wood | Step: 22\n",
      "Skill: wood | Step: 23\n",
      "Skill: wood | Step: 24\n",
      "Skill: wood | Step: 25\n",
      "Skill: wood | Step: 26\n",
      "Skill: wood | Step: 27\n",
      "Skill: wood | Step: 28\n",
      "Skill: wood | Step: 29\n",
      "\n",
      "Total steps: 30 Total reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Assumes these exist:\n",
    "# - CraftaxTopDownEnv, bc_models, act_greedy\n",
    "# - (Optional) get_pca_feat if your policy wants features instead of raw obs\n",
    "\n",
    "seeds = [6]\n",
    "\n",
    "for seed in seeds: \n",
    "    env = CraftaxTopDownEnv(\n",
    "        seed = seed, \n",
    "        goal_item=\"stone_pickaxe\",\n",
    "        goal_threshold=2,\n",
    "        goal_reward=1.0,\n",
    "        terminate_on_goal=True,\n",
    "        sparse_goal_reward=True,   # set to False to *add* +1 on top of env reward\n",
    "    )\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    all_obs = [obs.copy()]\n",
    "    all_actions = []\n",
    "\n",
    "    # Fixed skill schedule (8 steps each)\n",
    "    skill_order = [\n",
    "        \"wood\",\n",
    "    ]\n",
    "    STEPS_PER_SKILL = 30\n",
    "    MAX_STEPS = 150  # optional global cap\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    for skill_name in skill_order:\n",
    "        if done or t >= MAX_STEPS:\n",
    "            break\n",
    "\n",
    "        # Make sure we have a policy for this skill\n",
    "        if skill_name not in bc_models:\n",
    "            print(f\"[WARN] No bc_model found for '{skill_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        model, normalizer, device, n_actions = bc_models[skill_name]\n",
    "\n",
    "        print(f\"\\n=== Executing skill: {skill_name} ===\")\n",
    "        steps_this_skill = 0\n",
    "\n",
    "        while (steps_this_skill < STEPS_PER_SKILL) and (t < MAX_STEPS) and (not done):\n",
    "            print(\"Skill:\", skill_name, \"| Step:\", t)\n",
    "\n",
    "            # If your policy expects features, replace 'obs' with the appropriate transform:\n",
    "            # feats = get_pca_feat(obs)              # if needed\n",
    "            # action, probs = act_greedy(model, normalizer, device, feats)\n",
    "            action, probs = act_greedy(model, normalizer, device, obs)\n",
    "\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            all_obs.append(obs.copy())\n",
    "            all_actions.append(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            steps_this_skill += 1\n",
    "            t += 1\n",
    "\n",
    "    print(\"\\nTotal steps:\", t, \"Total reward:\", total_reward)\n",
    "\n",
    "\n",
    "\n",
    "    # Save observations as a GIF\n",
    "    frames = [(np.clip(f, 0, 1) * 255).astype(np.uint8) for f in all_obs]\n",
    "    imageio.mimsave(f\"craftax_run_test_seed_{seed}_{total_reward}.gif\", frames, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e042816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 274, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08bd247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e7b5e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.max(), obs.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc72e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hisd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
